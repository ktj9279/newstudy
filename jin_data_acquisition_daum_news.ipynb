{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import requests\n",
    "# from selenium import webdriver\n",
    "import sqlite3\n",
    "import time as time_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "press_list = ['daum', 'naver',\n",
    "              'seoulilbo', 'dtoday', 'asiailbo', 'labortoday', 'm-i',\n",
    "              'ekn', 'busan', 'imaeil', 'kookje', 'yeongnam']\n",
    "press_dict = {'daum':'다음', 'naver':'네이버',\n",
    "              'seoulilbo':'서울일보', 'dtoday':'일간투데이', 'asiailbo':'아시아일보',\n",
    "              'labortoday':'매일노동뉴스', 'm-i':'매일일보', 'ekn':'에너지경제',\n",
    "              'busan':'부산일보', 'imaeil':'매일신문', 'kookje':'국제신문',\n",
    "              'yeongnam':'영남일보'}\n",
    "\n",
    "daum_press_list = ['EBS', 'IT동아', 'JTBC', 'KBS', 'KTV',\n",
    "                   'MBC', 'MBN', 'SBS', 'SBS CNBC', 'YTN',\n",
    "                   'ZDNet Korea', 'bnt뉴스', '게임동아', '게임톡', '경향신문',\n",
    "                   '국민일보', '기자협회보', '노컷뉴스', '뉴스1', '뉴시스',\n",
    "                   '데일리안', '동아사이언스', '동아일보', '디지털타임스', '로이터',\n",
    "                   '매경게임진', '매일경제', '머니S', '머니투데이', '문화일보',\n",
    "                   '미디어오늘', '서울경제', '서울신문', '세계일보', '아시아경제',\n",
    "                   '아이뉴스24', '연합뉴스', '연합뉴스TV', '오마이뉴스', '오토타임즈',\n",
    "                   '이데일리', '전자신문', '조선비즈', '조선일보', '중앙일보',\n",
    "                   '채널A', '코리아헤럴드', '쿠키뉴스', '파이낸셜뉴스', '포토친구',\n",
    "                   '프레시안', '한겨레', '한국경제', '한국경제TV', '한국일보',\n",
    "                   '헤럴드경제']\n",
    "naver_press_list = ['JTBC', 'KBS', 'MBC', 'MBN', 'SBS',\n",
    "                    'SBS CNBC', 'TV조선', 'YTN', 'ZDNet Korea', '강원일보',\n",
    "                    '경향신문', '국민일보', '기자협회보', '노컷뉴스', '뉴스1',\n",
    "                    '뉴시스', '데일리안', '동아사이언스', '동아일보', '디지털데일리',\n",
    "                    '디지털타임스', '로이터', '매일경제', '매일신문', '머니S',\n",
    "                    '머니투데이', '문화일보', '미디어오늘', '부산일보', '블로터',\n",
    "                    '서울경제', '서울신문', '세계일보', '아시아경제', '아이뉴스24',\n",
    "                    '여성신문', '연합뉴스', '연합뉴스TV', '오마이뉴스', '이데일리',\n",
    "                    '일다', '전자신문', '조선비즈', '조선일보', '조세일보',\n",
    "                    '중앙일보', '참세상', '채널A', '코리아헤럴드', '코메디닷컴',\n",
    "                    '파이낸셜뉴스', '프레시안', '한겨레', '한국경제', '한국경제TV',\n",
    "                    '한국일보', '헤럴드경제', '헬스조선']\n",
    "\n",
    "section_list = ['society', 'politics', 'economic', 'culture', 'digital', 'global']\n",
    "section_dict = {'society':'사회', 'politics':'정치', 'economic':'경제',\n",
    "               'culture':'문화', 'digital':'IT', 'global':'세계'}\n",
    "\n",
    "base_urls = {'daum':\n",
    "             {'society':'http://media.daum.net/breakingnews/society',\n",
    "              'politics':'http://media.daum.net/breakingnews/politics',\n",
    "              'economic':'http://media.daum.net/breakingnews/economic',\n",
    "              'culture':'http://media.daum.net/breakingnews/culture',\n",
    "              'digital':'http://media.daum.net/breakingnews/digital',\n",
    "              'global':'http://media.daum.net/breakingnews/foreign'\n",
    "             },\n",
    "             'seoulilbo':\n",
    "             {'society':'http://www.seoulilbo.com/news/articleList.html?sc_section_code=S1N10&view_type=sm',\n",
    "              'politics':'http://www.seoulilbo.com/news/articleList.html?sc_section_code=S1N8&view_type=sm',\n",
    "              'economic':'http://www.seoulilbo.com/news/articleList.html?sc_section_code=S1N9&view_type=sm',\n",
    "              'culture':'http://www.seoulilbo.com/news/articleList.html?sc_section_code=S1N11&view_type=sm',\n",
    "              'digital':'',\n",
    "              'global':''\n",
    "             },\n",
    "             'dtoday':\n",
    "             {'society':'',\n",
    "              'politics':'http://www.dtoday.co.kr/news/articleList.html?sc_section_code=S1N1&view_type=sm',\n",
    "              'economic':'http://www.dtoday.co.kr/news/articleList.html?sc_section_code=S1N2&view_type=sm',\n",
    "              'culture':'',\n",
    "              'digital':'',\n",
    "              'global':''\n",
    "             },\n",
    "             'asiailbo':\n",
    "             {'society':'http://www.asiailbo.co.kr/etnews/?cid=21030000',\n",
    "              'politics':'http://www.asiailbo.co.kr/etnews/?cid=21010000',\n",
    "              'economic':'http://www.asiailbo.co.kr/etnews/?cid=21020000',\n",
    "              'culture':'http://www.asiailbo.co.kr/etnews/?cid=21040000',\n",
    "              'digital':'',\n",
    "              'global':''\n",
    "             },\n",
    "             'labortoday':\n",
    "             {'society':'http://www.labortoday.co.kr/news/articleList.html?sc_section_code=S1N3&view_type=sm',\n",
    "              'politics':'http://www.labortoday.co.kr/news/articleList.html?sc_section_code=S1N2&view_type=sm',\n",
    "              'economic':'',    # 정치, 경제\n",
    "              'culture':'',\n",
    "              'digital':'',\n",
    "              'global':''\n",
    "             },\n",
    "             'm-i':\n",
    "             {'society':'http://www.m-i.kr/news/articleList.html?sc_section_code=S1N3&view_type=sm',\n",
    "              'politics':'http://www.m-i.kr/news/articleList.html?sc_section_code=S1N1&view_type=tm',\n",
    "              'economic':'http://www.m-i.kr/news/articleList.html?sc_section_code=S1N2&view_type=sm',\n",
    "              'culture':'http://www.m-i.kr/news/articleList.html?sc_section_code=S1N22&view_type=tm',\n",
    "              'digital':'',\n",
    "              'global':''\n",
    "             },\n",
    "             'ekn':\n",
    "             {'society':'http://www.ekn.kr/news/section_list_all.html?sec_no=25',\n",
    "              'politics':'',    # 정치, 사회\n",
    "              'economic':'http://www.ekn.kr/news/section_list_all.html?sec_no=130',\n",
    "              'culture':'',\n",
    "              'digital':'',\n",
    "              'global':''\n",
    "             },\n",
    "             'busan':\n",
    "             {'society':'http://news20.busan.com/news/social.jsp',\n",
    "              'politics':'http://news20.busan.com/news/politics.jsp',\n",
    "              'economic':'http://news20.busan.com/EconomyAndOcean/econocean.jsp',\n",
    "              'culture':'http://news20.busan.com/news/culture.jsp',\n",
    "              'digital':'',\n",
    "              'global':''\n",
    "             },\n",
    "             'imaeil':\n",
    "             {'society':'http://news.imaeil.com/SocietyAll/',\n",
    "              'politics':'http://news.imaeil.com/PoliticsAll/',\n",
    "              'economic':'http://news.imaeil.com/EconomyAll/',\n",
    "              'culture':'http://news.imaeil.com/CultureAll/',\n",
    "              'digital':'',\n",
    "              'global':'http://news.imaeil.com/InternationalAll/'\n",
    "             },\n",
    "             'kookje':\n",
    "             {'society':'http://www.kookje.co.kr/sub.htm?code=0300&vHeadTitle=%BB%E7%C8%B8',\n",
    "              'politics':'http://www.kookje.co.kr/sub.htm?code=0100&vHeadTitle=%C1%A4%C4%A1',\n",
    "              'economic':'http://www.kookje.co.kr/sub.htm?code=0200&vHeadTitle=%B0%E6%C1%A6',\n",
    "              'culture':'http://www.kookje.co.kr/sub.htm?code=0500&vHeadTitle=%B9%AE%C8%AD',\n",
    "              'digital':'http://www.kookje.co.kr/sub.htm?code=0800&vHeadTitle=IT%B0%FA%C7%D0',\n",
    "              'global':'http://www.kookje.co.kr/sub.htm?code=0400&vHeadTitle=%B1%B9%C1%A6'\n",
    "             },\n",
    "             'yeongnam':\n",
    "             {'society':'http://www.yeongnam.com/mnews/newsview.do?mode=subMain&cId=04',\n",
    "              'politics':'http://www.yeongnam.com/mnews/newsview.do?mode=subMain&cId=02',\n",
    "              'economic':'http://www.yeongnam.com/mnews/newsview.do?mode=subMain&cId=03',\n",
    "              'culture':'http://www.yeongnam.com/mnews/newsview.do?mode=subMain&cId=08',\n",
    "              'digital':'',    # 교육, 과학\n",
    "              'global':'http://www.yeongnam.com/mnews/newsview.do?mode=subMain&cId=06'\n",
    "             }\n",
    "            }\n",
    "\n",
    "headers = {\"user-agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_ex = {'email':r'[a-zA-Z0-9.!#$%&\\'*+/=?^_`{|}~-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+'}\n",
    "\n",
    "#【.+=.+】.+=\n",
    "# (+=.+).+=\n",
    "\n",
    "stop_title_sb = ['[포토]', '[프로필]', '[★화보]', '[게시판]', '[경향포토]',\n",
    "              '[리빙포인트]', '[머니S포토]', '[부고]', '[부음]', '[사람 人 사람]',\n",
    "              '[사진]', '[서울포토]', '[영어]', \"[오래전 '이날']\", '[오마이포토]',\n",
    "              '[이 시각 코스피]', '[이 시각 코스닥]', '[인사]', '[코스닥 공시]', '[코스닥(개장)]',\n",
    "              '[코스닥(마감)]', '[코스피(개장)]', '[코스피(마감)]', '[포토뉴스]', '[표]',\n",
    "              '[한경로보뉴스]']\n",
    "\n",
    "stop_title_ = ['<부고>', '<오늘의 조간 정치뉴스>', '<인사>', '<포토>', '<코>', '<유>']\n",
    "\n",
    "stop_content = ['동영상 뉴스', '동영상뉴스']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DB\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('db/news_db.db')\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    cur.execute(\"CREATE TABLE daum(a_ids TEXT primary key, \\\n",
    "                dates DATE, times TIME, titles TEXT, contents TEXT, \\\n",
    "                press TEXT, authors TEXT, sections TEXT, urls TEXT)\")\n",
    "\n",
    "    conn.commit()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrap URLs\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_period(date_end_time_delta, day_period):\n",
    "    date_end = datetime.date.today() - datetime.timedelta(date_end_time_delta)\n",
    "    date_start = date_end - datetime.timedelta(day_period - 1)\n",
    "    \n",
    "    return  date_start, date_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_daum_news_urls(date_end_time_delta=1, day_period=7, page_limit=10000):\n",
    "    date_start, date_end = get_period(date_end_time_delta, day_period)\n",
    "    \n",
    "    press = 'daum'\n",
    "\n",
    "    # Section iteration\n",
    "    for section in section_list:\n",
    "        if base_urls[press][section] == '':\n",
    "            continue\n",
    "        else:\n",
    "            print(press, section_dict[section], base_urls[press][section])\n",
    "            print(date_start, ' - ', date_end)\n",
    "            print('--------------------------------------------------\\n')\n",
    "            \n",
    "            # Get section\n",
    "            section_ko = section_dict[section]\n",
    "\n",
    "            # Date iteration\n",
    "            for time_delta in range(day_period):\n",
    "                # Get date\n",
    "                date = str(date_end - datetime.timedelta(time_delta))\n",
    "                print(date)\n",
    "\n",
    "                urls = []\n",
    "                \n",
    "                # Page iteration\n",
    "                page = 1\n",
    "                while(True):\n",
    "                    if (page % 100) == 0:\n",
    "                        print('{0:6,} / {1:6,}'.format(page, page_limit))\n",
    "\n",
    "                    req_url = base_urls[press][section] + '?page=' + str(page) + '&regDate=' + date.replace('-', '')\n",
    "                    while(True):\n",
    "                        try:\n",
    "                            resp = requests.get(req_url, headers=headers, timeout=1)\n",
    "                        except:\n",
    "#                             print('Timeout: retry')\n",
    "                            continue\n",
    "                        else:\n",
    "                            break\n",
    "                        \n",
    "                    html = bs(resp.text, \"lxml\")\n",
    "\n",
    "                    url_html = html.select('#mArticle .tit_thumb > .link_txt')                \n",
    "\n",
    "                    urls_len = len(urls)\n",
    "                    \n",
    "                    # Get url\n",
    "                    for i in url_html:\n",
    "                        urls.append(i.get('href'))\n",
    "                        \n",
    "                    urls_len_diff = len(urls) - urls_len\n",
    "\n",
    "                    if page == page_limit:\n",
    "                        break\n",
    "                    elif urls_len_diff == 0:\n",
    "                        print('#', page, ': end of pages.')\n",
    "                        break\n",
    "                    else:    \n",
    "                        page += 1\n",
    "                \n",
    "                with open('db/urls/daum/' + press + '_' + section + '_' + date.replace('-', '') + '.pkl', 'wb') as f:\n",
    "                    pickle.dump(urls, f)\n",
    "\n",
    "            print('\\n--------------------------------------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scrap_daum_news_urls(1, 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Debug] Scrap URLs\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "press = 'daum'\n",
    "section = 'politics'\n",
    "date = '20180823'\n",
    "\n",
    "with open('db/urls/daum/' + press + '_' + section + '_' + date + '.pkl', 'rb') as f:\n",
    "    urls = pickle.load(f)\n",
    "    \n",
    "type(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://v.media.daum.net/v/20180823235953274',\n",
       " 'http://v.media.daum.net/v/20180823235712261',\n",
       " 'http://v.media.daum.net/v/20180823234956198',\n",
       " 'http://v.media.daum.net/v/20180823234929195',\n",
       " 'http://v.media.daum.net/v/20180823234832186',\n",
       " 'http://v.media.daum.net/v/20180823225456524',\n",
       " 'http://v.media.daum.net/v/20180823224023322',\n",
       " 'http://v.media.daum.net/v/20180823223902308',\n",
       " 'http://v.media.daum.net/v/20180823223627276',\n",
       " 'http://v.media.daum.net/v/20180823223304232']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrap News\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_daum_news(date_end_time_delta=1, day_period=7):\n",
    "    date_start, date_end = get_period(date_end_time_delta, day_period)\n",
    "    \n",
    "    press = 'daum'\n",
    "\n",
    "    for section in section_list:\n",
    "        if base_urls[press][section] == '':\n",
    "            continue\n",
    "        else:\n",
    "            print(press, section_dict[section], base_urls[press][section])\n",
    "            print(date_start, ' - ', date_end)\n",
    "            print('--------------------------------------------------\\n')\n",
    "            \n",
    "            # Get section\n",
    "            section_ko = section_dict[section]\n",
    "\n",
    "            # Date iteration\n",
    "            for time_delta in range(day_period):\n",
    "                # Get date\n",
    "                date = str(date_end - datetime.timedelta(time_delta))\n",
    "                print(date)\n",
    "\n",
    "                # Open url\n",
    "                with open('db/urls/daum/' + press + '_' + section + '_' + date.replace('-', '') + '.pkl', 'rb') as f:\n",
    "                    urls = pickle.load(f)\n",
    "                    \n",
    "                for idx, url in enumerate(urls):\n",
    "                    if (idx % 1000) == 0:\n",
    "                        print('{0:6,} / {1:6,}'.format(idx, len(urls)))\n",
    "\n",
    "                    while(True):\n",
    "                        try:\n",
    "                            resp = requests.get(url, headers=headers, timeout=1)\n",
    "#                             time_module.sleep(0.5)\n",
    "                        except:\n",
    "#                             print('Timeout: retry')\n",
    "                            continue\n",
    "                        else:\n",
    "                            break\n",
    "                                 \n",
    "                    html = bs(resp.text, \"lxml\")\n",
    "\n",
    "                    # Get id\n",
    "                    a_id = 'da_' + url[-17:]\n",
    "                    \n",
    "                    # Get time\n",
    "                    date_html = html.select('.head_view .info_view')\n",
    "#                         date = re.search(r'\\d{2,4}[.-]?\\d+[.-]?.\\d+', date_html[0].text).group(0)\n",
    "                    try:\n",
    "                        time = re.search(r'\\d+:\\d+', date_html[0].text).group(0)\n",
    "                    except:\n",
    "                        time = None\n",
    "                \n",
    "                    # Get title\n",
    "                    # title이 빈 문자열이면 해당 기사 제외\n",
    "                    title_html = html.select('.head_view .tit_view')\n",
    "                    try:\n",
    "                        title = title_html[0].text.strip()\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "                    # title에 한글이 하나도 없으면 해당 기사 제외\n",
    "                    if re.search(r'[ㄱ-ㅎㅏ-ㅣ가-힣]+', title) == None:\n",
    "                        continue\n",
    "                        \n",
    "                    # 특정 title 제거\n",
    "                    # TODO:\n",
    "                        \n",
    "                    content_html = html.select('.news_view #harmonyContainer')\n",
    "                    try:\n",
    "                        content = content_html[0].text.strip()\n",
    "                    except:\n",
    "                        content = None\n",
    "                        \n",
    "                    # content 중 기자 이메일부터 이하 내용 제거\n",
    "                    try:\n",
    "                        email_idx = re.search(reg_ex['email'], content).start()\n",
    "                        content_temp = content[:email_idx].strip()\n",
    "                        if (len(content_temp) / len(content)) > 0.6:\n",
    "                            content = content_temp\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    # content 중 ▶ 이하 내용 제거 (naver에 적용했던 코드이므로 수정해서 사용할 것)\n",
    "#                         tempIdx = cont.index('▶')\n",
    "#                         if tempIdx > 0:\n",
    "#                             cont = cont[:tempIdx]\n",
    "\n",
    "                    # Get author\n",
    "                    try:\n",
    "                        author = re.search(r'\\w+\\s*기자', content_html[0].text).group(0).replace(' 기자', '').replace('기자', '')\n",
    "                    except:\n",
    "                        author = None\n",
    "\n",
    "                    # Get press\n",
    "                    press_html = html.select('.head_view .thumb_g')\n",
    "                    try:\n",
    "                        press_ko = press_html[0].get('alt')\n",
    "                    except:\n",
    "                        press_ko = None\n",
    "\n",
    "                    # Insert data (row by row)\n",
    "                    data = (a_id, date, time, title, content, press_ko, author, section_ko, url)\n",
    "                    try:\n",
    "                        cur.execute(\"INSERT INTO daum(a_ids, dates, times, titles, contents, press, authors, sections, urls) \\\n",
    "                                    values(?,?,?,?,?,?,?,?,?)\", data)\n",
    "                    except:\n",
    "                        pass\n",
    "                    else:\n",
    "                        conn.commit()\n",
    "\n",
    "            print('\\n--------------------------------------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daum 사회 http://media.daum.net/breakingnews/society\n",
      "2018-08-23  -  2018-08-23\n",
      "--------------------------------------------------\n",
      "\n",
      "2018-08-23\n",
      "     0 /  7,994\n",
      "422 http://v.media.daum.net/v/20180823204846614\n",
      "674 http://v.media.daum.net/v/20180823194519386\n",
      " 1,000 /  7,994\n",
      " 2,000 /  7,994\n",
      " 3,000 /  7,994\n",
      " 4,000 /  7,994\n",
      " 5,000 /  7,994\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-babd22f995da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscrap_daum_news\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-9ebf88748849>\u001b[0m in \u001b[0;36mscrap_daum_news\u001b[1;34m(date_end_time_delta, day_period)\u001b[0m\n\u001b[0;32m    101\u001b[0m                         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                         \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n--------------------------------------------------\\n\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scrap_daum_news(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 에러 발생 시 DB의 특정 section data 삭제\n",
    "# conn = sqlite3.connect('db/news_db.db')\n",
    "# cur = conn.cursor()\n",
    "\n",
    "# cur.execute(\"DELETE FROM daum WHERE sections='IT'\")\n",
    "\n",
    "# conn.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
