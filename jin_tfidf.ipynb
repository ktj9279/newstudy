{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from konlpy.tag import Kkma\n",
    "from math import log2, log10\n",
    "import nltk\n",
    "import pickle\n",
    "import re\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = Kkma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_list = ['society', 'politics', 'economic', 'culture', 'digital', 'global']\n",
    "section_dict = {'society':'사회', 'politics':'정치', 'economic':'경제',\n",
    "               'culture':'문화', 'digital':'IT', 'global':'세계'}\n",
    "\n",
    "date_list = ['2018-08-23', '2018-08-22', '2018-08-21', '2018-08-20', '2018-08-19', '2018-08-18', '2018-08-17',\n",
    "             '2018-08-16', '2018-08-15', '2018-08-14', '2018-08-13', '2018-08-12', '2018-08-11', '2018-08-10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_ratio = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 주요 변수\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임시로 데이터를 보관하는 변수. DB 또는 pickle로 저장함.\n",
    "# 여러 개의 기준이 있을 수 있음. 주석 참조.\n",
    "a_nouns_tf = {}          # Article\n",
    "a_noun_max_cnt = {}      # Article\n",
    "inverted_idx = {}        # 전체, 기간, section + 기간\n",
    "unique_nouns_idf = {}    # 전체, 기간, section + 기간"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 이 형태 아님. 맨 앞에 section으로 된 key 빼야 함.\n",
    "\n",
    "\n",
    "**a_nouns_tf**  \n",
    "{'society': {'da_20180822201040252': {'인천': 0.1, '남동': 0.5, '남동공단': 0.8, ...}  \n",
    "...  \n",
    "}}\n",
    "\n",
    "\n",
    "**a_noun_max_cnt**  \n",
    "{'society': {'da_20180822201040252': 4, 'da_20180822201030249': 20, 'da_20180822200910228': 3, ...}  \n",
    "...  \n",
    "}\n",
    "\n",
    "\n",
    "**inverted_idx**  \n",
    "{'society': {'김영호': ['da_20180822194016575'],  \n",
    "'심상치가': ['da_20180822194312638'],  \n",
    "'최우수': ['da_20180822192938304', 'da_20180822191858060'], ...}  \n",
    "...  \n",
    "}\n",
    "\n",
    "\n",
    "**unique_nouns_idf**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DB\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('db/news_db.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    cur.execute(\"CREATE TABLE Term( \\\n",
    "                a_t_id      INTEGER PRIMARY KEY, \\\n",
    "                a_id        TEXT, \\\n",
    "                term        TEXT, \\\n",
    "                tf_article  REAL, \\\n",
    "                tfidf       REAL, \\\n",
    "                FOREIGN KEY (a_id) REFERENCES Article(a_id))\")\n",
    "\n",
    "    conn.commit()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur.execute(\"DROP TABLE Term\")\n",
    "\n",
    "# conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 불용어 제거\n",
    "---\n",
    "\n",
    "* by 한홀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def NewsStopWord(word):\n",
    "    try:\n",
    "        int(word) #숫자일경우\n",
    "    except:        \n",
    "        if type(word) is str and word.__contains__('회차'):\n",
    "            return True\n",
    "        if len(word) == 1:\n",
    "            # 한글자 빠짐\n",
    "            return True\n",
    "        if re.search(r'\\d+',word) != None:\n",
    "            # 숫자가 하나라도 포함되면\n",
    "            return True\n",
    "               \n",
    "        newsDic = {\"기자\":1,\"배포\":1,\"금지\":1,\"뉴스\":1,\"저작권자\":1,\n",
    "                   \"기사\":1,\"전재\":1,\"무단\":1,\"무단전재\":1,\"구독\":1,\"기사보기\":1}\n",
    "        \n",
    "        pressDic = {'연합뉴스':1,'뉴시스':1,'뉴시스통신사':1,'통신사':1,\n",
    "                    '이데일리':1,'네이버':1,'다음':1,'시스':1,'뉴스1':1,'뉴스1코리':1}\n",
    "        \n",
    "        nothingDic = {'사진':1,'페이스북':1,'관련':1,'웹툰보기':1,'가기':1,'만큼':1,\n",
    "                     '최근':1,'재인':1,'올해':1,'시간':1,'판단':1,'추진':1,'우리':1,'반영':1,\n",
    "                      '상황':1,'호텔':1,'운영':1,'주요':1,'적극':1,'대상':1,'때문':1,\n",
    "                      '확인':1,'가능':1,'이야기':1,'규모':1,'개월':1,'종합':1,'위원회':1,\n",
    "                      '가운데':1,'분석':1,'다양':1,'문제':1,'기간':1,'마련':1,'지난해':1,'신청':1,'한편':1,'기준':1,\n",
    "                      '내용':1,'채널설정':1,'경우':1,'방안':1,'활용':1,'여러분':1,'기존':1,'최대':1,'스냅':1,'오전':1,'대비':1,\n",
    "                      '위원':1,'지난달':1,'이번달':1,'다음달':1,'위원장':1,'센터':1,'포함':1,'등에':1,'사진영상부':1,\n",
    "                      '구성':1,'수준':1,'기대':1,'공동':1,'안내':1,'활동':1,'첫날':1,'추가':1,'분야':1,'관리':1,\n",
    "                      '동안':1,'이용':1,'모습':1,'오늘':1,'논의':1,'입장':1,'업계':1,'내년':1,'블록':1,'체인':1,'실시간':1,\n",
    "                      '고객':1,'채널':1,'보기':1,'오후':1,'이번':1,'이날':1,'진행':1,'제공':1,'예정':1,'연합':1,'대표':1,\n",
    "                      '제보':1,'이상':1,'지원':1,'행사':1,'관계자':1,'설정':1,'계획':1,'단체':1,'타임':1,'이후':1,'발표':1\n",
    "                     }\n",
    "        if word in newsDic.keys() or word in pressDic.keys() or word in nothingDic.keys():\n",
    "            return True\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Nouns and Compute Term Frequency (TF)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(obj):\n",
    "    try:\n",
    "        float(obj)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf(a_id, content):\n",
    "    a_nouns_tf[a_id] = {}\n",
    "    nouns_cnt = {}\n",
    "    a_noun_max_cnt[a_id] = 0\n",
    "\n",
    "    # 연속된 공백 및 개행 제거\n",
    "    content = re.sub(r'[\\s]{2,}', ' ', content)\n",
    "    content = re.sub(r'[\\n]{2,}', '\\n', content)\n",
    "\n",
    "    # 문장 단위 토큰화\n",
    "    for idx, sentence in enumerate(nltk.sent_tokenize(content)):\n",
    "        nouns_temp = []\n",
    "\n",
    "        # 단어 단위 토큰화\n",
    "        for word in nltk.word_tokenize(sentence.strip()):\n",
    "            # 명사 추출\n",
    "            nouns = k.nouns(word)\n",
    "\n",
    "            for noun in nouns:\n",
    "                # 불용어 제거\n",
    "                if NewsStopWord(noun):\n",
    "                    continue\n",
    "\n",
    "                if noun in nouns_cnt.keys():\n",
    "                    nouns_cnt[noun] += 1\n",
    "                else:\n",
    "                    nouns_cnt[noun] = 1\n",
    "\n",
    "                if a_noun_max_cnt[a_id] < nouns_cnt[noun]:\n",
    "                    a_noun_max_cnt[a_id] = nouns_cnt[noun]\n",
    "\n",
    "#             # 기본 불용어 제거\n",
    "#             for stop_word in stop_words:\n",
    "#                 nouns.remove(stop_word)\n",
    "\n",
    "#             nouns_temp.extend(nouns)\n",
    "#             nouns_temp = list(set(nouns_temp))\n",
    "\n",
    "#         unique_nouns.extend(nouns_temp)\n",
    "#         unique_nouns = list(set(unique_nouns))\n",
    "\n",
    "    for noun in nouns_cnt.keys():\n",
    "        a_nouns_tf[a_id][noun] = k_ratio + (1 - k_ratio) * nouns_cnt[noun] / a_noun_max_cnt[a_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert Nouns and TFs into Term Table\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('db/news_db.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Date iteration\n",
    "# 기사 수가 너무 많아서 날짜별로 분할하여 처리\n",
    "for date in date_list:\n",
    "    print(date)\n",
    "    print('--------------------------------------------------\\n')\n",
    "    \n",
    "    a_nouns_tf = {}\n",
    "    a_noun_max_cnt = {}\n",
    "    \n",
    "    cur.execute(\"SELECT a_id, content FROM Article WHERE date = '{0}'\".format(date))\n",
    "\n",
    "    data = cur.fetchall()\n",
    "    \n",
    "    # Content iteration\n",
    "    for data_idx, d in enumerate(data):\n",
    "        if (data_idx % 5000) == 0:\n",
    "            print('{0:6,} / {1:6,}'.format(data_idx, len(data)))\n",
    "        \n",
    "        compute_tf(a_id=d[0], content=d[1])\n",
    "        \n",
    "    # Insert data\n",
    "    for a_id, nouns_tf in a_nouns_tf.items():\n",
    "        for noun, tf in nouns_tf.items():\n",
    "            data = (a_id, noun, tf)\n",
    "            try:\n",
    "                cur.execute(\"INSERT INTO Term(a_id, term, tf_article) \\\n",
    "                            VALUES(?,?,?)\", data)\n",
    "            except:\n",
    "                pass\n",
    "            else:\n",
    "                conn.commit()\n",
    "\n",
    "    print('\\n--------------------------------------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Debug] Extract Nouns and Compute Term Frequency (TF)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a_nouns_tf = {}\n",
    "# a_noun_max_cnt = {}\n",
    "\n",
    "# a_id = 'da_20180823143529578'\n",
    "# content = \"\"\"제19호 태풍 ‘솔릭’이 제주도를 지나 북상하면서 광주 지역 모든 학교 학생들이 조기 하교 했다. 항공편은 모두 결항됐으며 무등산 입산이 통제됐다. \n",
    "\n",
    "#            23일 오후 광주 서구 하늘에 제19호 태풍 솔릭이 몰고온 먹구름이 가득하다.\n",
    "          \n",
    "\n",
    "# 23일 광주지방기상청에 따르면 제19호 태풍 ‘솔릭’은 이날 낮 12시 현재 제주 서귀포 서쪽 90km 부근 해상에서 시속 4km로 북진 하고 있다. 기상청은 태풍이 이날 오후 6시쯤 목포 서남쪽 80㎞ 해상을 지난뒤 오는 24일 새벽 전북 군산 인근으로 상륙할 것으로 보고 있다. \n",
    "# 솔릭이 예상보다 훨씬 느린 속도로 접근하면서 광주 시민들은 ‘조마조마’한 심정으로 피해 예방을 위해 총력을 다했다. 태풍의 영향으로 광주 지역에는 바람이 점차 강해지면서 이날 제주와 김포를 오가는 광주공항의 모든 항공편이 결항됐다. 무등산도 입산이 통제됐다. \n",
    "# 태풍이 접근하면서 광주시교육청은 전체 학교를 대상으로 ‘조기 하교’를 결정했다. 광주지역 유치원과 초·중·고는 오후 3시 이전에 조기 하교했다. 고등학교의 아간 자율학습도 금지됐다. 교육청은 학원에도 휴원을 적극 검토하고 하원 시간을 조정하도록 요청했다. \n",
    "# 광주·전남은 24일까지 100∼250㎜의 비가 내리고 해안과 지리산에는 400㎜ 넘게 내리는 곳도 있겠다. 광주·전남은 태풍의 중심에서 반경 25m 범위 안에 들어 바람도 강하게 불 것으로 기상청은 내다보고 있다.\"\"\"\n",
    "\n",
    "# compute_tf(a_id, content)\n",
    "\n",
    "# a_nouns_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# conn = sqlite3.connect('db/daum.db')\n",
    "# cur = conn.cursor()\n",
    "\n",
    "# # Date iteration\n",
    "# # 기사 수가 너무 많아서 날짜별로 분할하여 처리\n",
    "# for date in date_list:\n",
    "#     date = date.replace('-', '.')\n",
    "#     print(date)\n",
    "#     print('--------------------------------------------------\\n')\n",
    "    \n",
    "#     a_nouns_tf = {}\n",
    "#     a_noun_max_cnt = {}\n",
    "    \n",
    "#     cur.execute(\"SELECT a_ids, contents FROM daum WHERE dates = '{0}'\".format(date))\n",
    "\n",
    "#     data = cur.fetchall()\n",
    "    \n",
    "#     # Content iteration\n",
    "#     for data_idx, d in enumerate(data):\n",
    "#         if (data_idx % 2000) == 0:\n",
    "#             print('{0:6,} / {1:6,}'.format(data_idx, len(data)))\n",
    "        \n",
    "#         compute_tf(a_id=d[0], content=d[1])\n",
    "        \n",
    "#     # Insert data\n",
    "#     for a_id, nouns_tf in a_nouns_tf.items():\n",
    "#         for noun, tf in nouns_tf.items():\n",
    "#             data = (a_id, noun, tf)\n",
    "#             try:\n",
    "#                 cur.execute(\"INSERT INTO Term(a_id, term, tf_article) \\\n",
    "#                             VALUES(?,?,?)\", data)\n",
    "#             except:\n",
    "#                 pass\n",
    "#         else:\n",
    "#             conn.commit()\n",
    "\n",
    "#     print('\\n--------------------------------------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Unique Nouns, Invert Index and\n",
    "## Compute Inverse Document Frequency (IDF)\n",
    "---\n",
    "\n",
    "* Inverted index and IDF (전체)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0 /      2,781\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('db/news_db.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "inverted_idx = {}\n",
    "unique_nouns_idf = {}\n",
    "\n",
    "cur.execute(\"SELECT a_id, term FROM Term\")\n",
    "\n",
    "data = cur.fetchall()\n",
    "\n",
    "# Noun iteration\n",
    "for data_idx, d in enumerate(data):\n",
    "    if (data_idx % 100000) == 0:\n",
    "        print('{0:10,} / {1:10,}'.format(data_idx, len(data)))\n",
    "    \n",
    "    noun = d[1]\n",
    "    a_id = d[0]\n",
    "    \n",
    "    if noun in inverted_idx.keys():\n",
    "        inverted_idx[noun].append(a_id)\n",
    "    else:\n",
    "        inverted_idx[noun] = []\n",
    "        inverted_idx[noun].append(a_id)\n",
    "\n",
    "cur.execute(\"SELECT COUNT(*) FROM Article\")\n",
    "\n",
    "a_size = cur.fetchone()[0]\n",
    "        \n",
    "for noun, a_ids in inverted_idx.items():\n",
    "    df = len(a_ids)\n",
    "    unique_nouns_idf[noun] = log10(a_size / df)\n",
    "        \n",
    "with open('index/inverted_index/inverted_index.pkl', 'wb') as f:\n",
    "    pickle.dump(inverted_idx, f)\n",
    "    \n",
    "with open('index/unique_nouns_idf/unique_nouns_idf.pkl', 'wb') as f:\n",
    "    pickle.dump(unique_nouns_idf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique nouns:  2063 \n",
      "\n",
      "화재\n",
      "DF:  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['da_20180823235953274', 'da_20180818235833634', 'da_20180810234631844']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [Debug] Inverted index\n",
    "unique_noun = tuple(inverted_idx.keys())[0]\n",
    "\n",
    "print('The number of unique nouns: ', len(inverted_idx), '\\n')\n",
    "print(unique_noun)\n",
    "print('DF: ', len(inverted_idx[unique_noun]))\n",
    "inverted_idx[unique_noun][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of IDF unique nouns:  2063 \n",
      "\n",
      "화재 |  4.66\n",
      "화재원인 |  5.14\n",
      "원인 |  4.36\n",
      "어디 |  4.84\n",
      "인천 |  4.44\n",
      "윤태현 |  5.14\n",
      "태현 |  5.14\n",
      "인천시 |  5.14\n",
      "남동 |  5.14\n",
      "남동구 |  5.14\n"
     ]
    }
   ],
   "source": [
    "# [Debug] Unique nouns IDF\n",
    "unique_nouns = tuple(unique_nouns_idf.keys())[:10]\n",
    "\n",
    "print('The number of IDF unique nouns: ', len(unique_nouns_idf), '\\n')\n",
    "for unique_noun in unique_nouns:\n",
    "    print('{0} | {1:5.3}'.format(unique_noun, unique_nouns_idf[unique_noun]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Inverted index and IDF (기간)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2018-08-23', '2018-08-22', '2018-08-21', '2018-08-20', '2018-08-19', '2018-08-18', '2018-08-17']\n",
      "['2018-08-22', '2018-08-21', '2018-08-20', '2018-08-19', '2018-08-18', '2018-08-17', '2018-08-16']\n",
      "['2018-08-21', '2018-08-20', '2018-08-19', '2018-08-18', '2018-08-17', '2018-08-16', '2018-08-15']\n",
      "['2018-08-20', '2018-08-19', '2018-08-18', '2018-08-17', '2018-08-16', '2018-08-15', '2018-08-14']\n",
      "['2018-08-19', '2018-08-18', '2018-08-17', '2018-08-16', '2018-08-15', '2018-08-14', '2018-08-13']\n",
      "['2018-08-18', '2018-08-17', '2018-08-16', '2018-08-15', '2018-08-14', '2018-08-13', '2018-08-12']\n",
      "['2018-08-17', '2018-08-16', '2018-08-15', '2018-08-14', '2018-08-13', '2018-08-12', '2018-08-11']\n",
      "['2018-08-16', '2018-08-15', '2018-08-14', '2018-08-13', '2018-08-12', '2018-08-11', '2018-08-10']\n"
     ]
    }
   ],
   "source": [
    "# [Debug]\n",
    "for date_idx in range(len(date_list)-6):\n",
    "    print(date_list[date_idx:date_idx+7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-23 |      1,152 |     71,079\n",
      "         0 /      1,152\n",
      "2018-08-22 |      1,292 |     71,510\n",
      "         0 /      1,292\n",
      "2018-08-21 |      1,423 |     65,391\n",
      "         0 /      1,423\n",
      "2018-08-20 |      1,587 |     65,239\n",
      "         0 /      1,587\n",
      "2018-08-19 |      1,488 |     65,999\n",
      "         0 /      1,488\n",
      "2018-08-18 |      1,456 |     65,690\n",
      "         0 /      1,456\n",
      "2018-08-17 |      1,617 |     65,640\n",
      "         0 /      1,617\n",
      "2018-08-16 |      1,629 |     66,006\n",
      "         0 /      1,629\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('db/news_db.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Date (기간) iteration\n",
    "for date_idx in range(len(date_list)-6):\n",
    "    inverted_idx = {}\n",
    "    unique_nouns_idf = {}\n",
    "    \n",
    "    data = []\n",
    "    a_size = 0\n",
    "    \n",
    "    # Date (기간에 속하는 각 날짜) iteration\n",
    "    for date in date_list[date_idx:date_idx+7]:\n",
    "        cur.execute(\"SELECT T.a_id, T.term \\\n",
    "                    From Article A, Term T \\\n",
    "                    WHERE A.a_id = T.a_id AND A.date = '{0}'\".format(date))\n",
    "\n",
    "        data.extend(cur.fetchall())\n",
    "        \n",
    "        cur.execute(\"SELECT COUNT(*) FROM Article WHERE date = '{0}'\".format(date))\n",
    "\n",
    "        a_size += cur.fetchone()[0]\n",
    "\n",
    "    print('{0} | {1:10,} | {2:10,}'.format(date_list[date_idx], len(data), a_size))\n",
    "        \n",
    "    # Noun iteration\n",
    "    for data_idx, d in enumerate(data):\n",
    "        if (data_idx % 100000) == 0:\n",
    "            print('{0:10,} / {1:10,}'.format(data_idx, len(data)))\n",
    "\n",
    "        noun = d[1]\n",
    "        a_id = d[0]\n",
    "\n",
    "        if noun in inverted_idx.keys():\n",
    "            inverted_idx[noun].append(a_id)\n",
    "        else:\n",
    "            inverted_idx[noun] = []\n",
    "            inverted_idx[noun].append(a_id)\n",
    "            \n",
    "    for noun, a_ids in inverted_idx.items():\n",
    "        df = len(a_ids)\n",
    "        unique_nouns_idf[noun] = log10(a_size / df)\n",
    "\n",
    "    with open('index/inverted_index/inverted_index_' + date_list[date_idx] + '.pkl', 'wb') as f:\n",
    "        pickle.dump(inverted_idx, f)\n",
    "        \n",
    "    with open('index/unique_nouns_idf/unique_nouns_idf_' + date_list[date_idx] + '.pkl', 'wb') as f:\n",
    "        pickle.dump(unique_nouns_idf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique nouns:  944 \n",
      "\n",
      "화재\n",
      "DF:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['da_20180823235953274', 'da_20180818235833634']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [Debug] Inverted index\n",
    "date = '2018-08-23'\n",
    "\n",
    "with open('index/inverted_index/inverted_index_{0}.pkl'.format(date), 'rb') as f:\n",
    "    inverted_idx = pickle.load(f)\n",
    "\n",
    "unique_noun = tuple(inverted_idx.keys())[0]\n",
    "\n",
    "print('The number of unique nouns: ', len(inverted_idx), '\\n')\n",
    "print(unique_noun)\n",
    "print('DF: ', len(inverted_idx[unique_noun]))\n",
    "inverted_idx[unique_noun][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of IDF unique nouns:  944 \n",
      "\n",
      "화재 |  4.55\n",
      "화재원인 |  4.85\n",
      "원인 |  4.37\n",
      "어디 |  4.85\n",
      "인천 |  4.25\n",
      "윤태현 |  4.85\n",
      "태현 |  4.85\n",
      "인천시 |  4.85\n",
      "남동 |  4.85\n",
      "남동구 |  4.85\n"
     ]
    }
   ],
   "source": [
    "# [Debug] Unique nouns IDF\n",
    "date = '2018-08-23'\n",
    "\n",
    "with open('index/unique_nouns_idf/unique_nouns_idf_{0}.pkl'.format(date), 'rb') as f:\n",
    "    unique_nouns_idf = pickle.load(f)\n",
    "    \n",
    "unique_nouns = tuple(unique_nouns_idf.keys())[:10]\n",
    "\n",
    "print('The number of IDF unique nouns: ', len(unique_nouns_idf), '\\n')\n",
    "for unique_noun in unique_nouns:\n",
    "    print('{0} | {1:5.3}'.format(unique_noun, unique_nouns_idf[unique_noun]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Inverted index and IDF (section + 기간)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "society | 2018-08-23 | 1,152\n",
      "society | 2018-08-22 | 1,292\n",
      "society | 2018-08-21 | 1,423\n",
      "society | 2018-08-20 | 1,587\n",
      "society | 2018-08-19 | 1,488\n",
      "society | 2018-08-18 | 1,456\n",
      "society | 2018-08-17 | 1,617\n",
      "society | 2018-08-16 | 1,629\n",
      "politics | 2018-08-23 | 0\n",
      "politics | 2018-08-22 | 0\n",
      "politics | 2018-08-21 | 0\n",
      "politics | 2018-08-20 | 0\n",
      "politics | 2018-08-19 | 0\n",
      "politics | 2018-08-18 | 0\n",
      "politics | 2018-08-17 | 0\n",
      "politics | 2018-08-16 | 0\n",
      "economic | 2018-08-23 | 0\n",
      "economic | 2018-08-22 | 0\n",
      "economic | 2018-08-21 | 0\n",
      "economic | 2018-08-20 | 0\n",
      "economic | 2018-08-19 | 0\n",
      "economic | 2018-08-18 | 0\n",
      "economic | 2018-08-17 | 0\n",
      "economic | 2018-08-16 | 0\n",
      "culture | 2018-08-23 | 0\n",
      "culture | 2018-08-22 | 0\n",
      "culture | 2018-08-21 | 0\n",
      "culture | 2018-08-20 | 0\n",
      "culture | 2018-08-19 | 0\n",
      "culture | 2018-08-18 | 0\n",
      "culture | 2018-08-17 | 0\n",
      "culture | 2018-08-16 | 0\n",
      "digital | 2018-08-23 | 0\n",
      "digital | 2018-08-22 | 0\n",
      "digital | 2018-08-21 | 0\n",
      "digital | 2018-08-20 | 0\n",
      "digital | 2018-08-19 | 0\n",
      "digital | 2018-08-18 | 0\n",
      "digital | 2018-08-17 | 0\n",
      "digital | 2018-08-16 | 0\n",
      "global | 2018-08-23 | 0\n",
      "global | 2018-08-22 | 0\n",
      "global | 2018-08-21 | 0\n",
      "global | 2018-08-20 | 0\n",
      "global | 2018-08-19 | 0\n",
      "global | 2018-08-18 | 0\n",
      "global | 2018-08-17 | 0\n",
      "global | 2018-08-16 | 0\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('db/news_db.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Section interation\n",
    "for section in section_list:\n",
    "    # Date (기간) iteration\n",
    "    for date_idx in range(len(date_list)-6):\n",
    "        inverted_idx = {}\n",
    "        unique_nouns_idf = {}\n",
    "        \n",
    "        data = []\n",
    "        a_size = 0\n",
    "    \n",
    "        # Date (기간에 속하는 각 날짜) iteration\n",
    "        for date in date_list[date_idx:date_idx+7]:\n",
    "            cur.execute(\"SELECT T.a_id, T.term \\\n",
    "                        From Article A, Term T \\\n",
    "                        WHERE A.a_id = T.a_id AND A.section = '{0}' AND A.date = '{1}'\".format(section_dict[section], date))\n",
    "\n",
    "            data.extend(cur.fetchall())\n",
    "            \n",
    "            cur.execute(\"SELECT COUNT(*) FROM Article WHERE section = '{0}' AND date = '{1}'\".format(section_dict[section], date))\n",
    "\n",
    "            a_size += cur.fetchone()[0]\n",
    "\n",
    "        print('{0} | {1} | {2:10,} | {3:10,}'.format(section, date_list[date_idx], len(data), a_size))\n",
    "\n",
    "        # Noun iteration\n",
    "        for data_idx, d in enumerate(data):\n",
    "#             if (data_idx % 100000) == 0:\n",
    "#                 print('{0:10,} / {1:10,}'.format(data_idx, len(data)))\n",
    "\n",
    "            noun = d[1]\n",
    "            a_id = d[0]\n",
    "\n",
    "            if noun in inverted_idx.keys():\n",
    "                inverted_idx[noun].append(a_id)\n",
    "            else:\n",
    "                inverted_idx[noun] = []\n",
    "                inverted_idx[noun].append(a_id)\n",
    "                \n",
    "        for noun, a_ids in inverted_idx.items():\n",
    "            df = len(a_ids)\n",
    "            unique_nouns_idf[noun] = log10(a_size / df)\n",
    "\n",
    "        with open('index/inverted_index/inverted_index_' + section + '_' + date_list[date_idx] + '.pkl', 'wb') as f:\n",
    "            pickle.dump(inverted_idx, f)\n",
    "            \n",
    "        with open('index/unique_nouns_idf/unique_nouns_idf_' + section + '_' + date_list[date_idx] + '.pkl', 'wb') as f:\n",
    "            pickle.dump(unique_nouns_idf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique nouns:  944 \n",
      "\n",
      "화재\n",
      "DF:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['da_20180823235953274', 'da_20180818235833634']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [Debug]\n",
    "section = 'society'\n",
    "date = '2018-08-23'\n",
    "\n",
    "with open('index/inverted_index/inverted_index_{0}_{1}.pkl'.format(section, date), 'rb') as f:\n",
    "    inverted_idx = pickle.load(f)\n",
    "    \n",
    "unique_noun = tuple(inverted_idx.keys())[0]\n",
    "\n",
    "print('The number of unique nouns: ', len(inverted_idx), '\\n')\n",
    "print(unique_noun)\n",
    "print('DF: ', len(inverted_idx[unique_noun]))\n",
    "inverted_idx[unique_noun][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of IDF unique nouns:  944 \n",
      "\n",
      "화재 |  4.15\n",
      "화재원인 |  4.45\n",
      "원인 |  3.97\n",
      "어디 |  4.45\n",
      "인천 |  3.85\n",
      "윤태현 |  4.45\n",
      "태현 |  4.45\n",
      "인천시 |  4.45\n",
      "남동 |  4.45\n",
      "남동구 |  4.45\n"
     ]
    }
   ],
   "source": [
    "# [Debug] Unique nouns IDF\n",
    "section = 'society'\n",
    "date = '2018-08-23'\n",
    "\n",
    "with open('index/unique_nouns_idf/unique_nouns_idf_{0}_{1}.pkl'.format(section, date), 'rb') as f:\n",
    "    unique_nouns_idf = pickle.load(f)\n",
    "    \n",
    "unique_nouns = tuple(unique_nouns_idf.keys())[:10]\n",
    "\n",
    "print('The number of IDF unique nouns: ', len(unique_nouns_idf), '\\n')\n",
    "for unique_noun in unique_nouns:\n",
    "    print('{0} | {1:5.3}'.format(unique_noun, unique_nouns_idf[unique_noun]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert IDFs into Term Table\n",
    "---\n",
    "\n",
    "* DB에는 2018-08-23만 기록 (2018-08-17 - 2018-08-23)\n",
    "* 기간(1주일)마다 pickle 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0 /        944\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('db/news_db.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "date = '2018-08-23'\n",
    "unique_nouns_idf = {}\n",
    "\n",
    "with open('index/unique_nouns_idf/unique_nouns_idf_{0}.pkl'.format(date), 'rb') as f:\n",
    "    unique_nouns_idf = pickle.load(f)\n",
    "\n",
    "for unique_noun_idx, item in enumerate(unique_nouns_idf.items()):\n",
    "    if (unique_noun_idx % 10000) == 0:\n",
    "        print('{0:10,} / {1:10,}'.format(unique_noun_idx, len(unique_nouns_idf)))\n",
    "    \n",
    "    unique_noun = item[0]\n",
    "    idf = item[1]\n",
    "    \n",
    "    cur.execute(\"SELECT T.a_t_id, T.tf_article \\\n",
    "                FROM Article A, Term T \\\n",
    "                WHERE A.a_id = T.a_id AND A.date = '{0}' AND T.term = '{1}'\".format(date, unique_noun))\n",
    "\n",
    "    data = cur.fetchall()\n",
    "    \n",
    "    for d in data:\n",
    "        a_t_id = d[0]\n",
    "        tf = d[1]\n",
    "        \n",
    "        cur.execute(\"UPDATE Term \\\n",
    "                    SET tfidf = {0} \\\n",
    "                    WHERE a_t_id = {1}\"\n",
    "                    .format(tf * idf, a_t_id))\n",
    "    else:\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # [Debug]\n",
    "# conn = sqlite3.connect('db/daum.db')\n",
    "# cur = conn.cursor()\n",
    "\n",
    "# unique_nouns_idf = {'태풍': 1., '솔릭': 100., '제주': 10000.}\n",
    "\n",
    "# for unique_noun_idx, item in enumerate(unique_nouns_idf.items()):\n",
    "#     if (unique_noun_idx % 10000) == 0:\n",
    "#         print('{0:10,} / {1:10,}'.format(unique_noun_idx, len(unique_nouns_idf)))\n",
    "    \n",
    "#     unique_noun = item[0]\n",
    "#     idf = item[1]\n",
    "#     print(unique_noun, idf)\n",
    "    \n",
    "#     cur.execute(\"SELECT a_t_id, tf_article FROM Term WHERE term = '{0}'\".format(unique_noun))\n",
    "\n",
    "#     data = cur.fetchall()\n",
    "    \n",
    "#     for d in data:\n",
    "#         a_t_id = d[0]\n",
    "#         tf = d[1]\n",
    "        \n",
    "#         cur.execute(\"UPDATE Term \\\n",
    "#                     SET tfidf = {0} \\\n",
    "#                     WHERE a_t_id = {1}\"\n",
    "#                     .format(tf * idf, a_t_id))\n",
    "#     else:\n",
    "#         conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create U_Term Table and\n",
    "## Insert Unique Nouns and IDFs into the Table\n",
    "---\n",
    "\n",
    "* DB에는 2018-08-23만 기록 (2018-08-17 - 2018-08-23)\n",
    "* 기간(1주일)마다 pickle 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_term, idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump Pickles\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 위 셀 코딩 중. 아래는 예전 코드이므로 참고만!\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-23\n",
      "2018-08-22\n",
      "2018-08-21\n",
      "2018-08-20\n",
      "2018-08-19\n",
      "2018-08-18\n",
      "2018-08-17\n",
      "2018-08-16\n"
     ]
    }
   ],
   "source": [
    "for date in date_list[:-6]:\n",
    "    print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverted_index(db_name, table_name, sections=['society', 'politics', 'economic', 'culture', 'digital', 'global'], write=False):\n",
    "    k = Kkma()\n",
    "    \n",
    "    conn = sqlite3.connect('db/' + db_name + '.db')\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    for section in sections:\n",
    "        print(section_dict[section])\n",
    "        print('--------------------------------------------------\\n')\n",
    "\n",
    "        cur.execute(\"SELECT a_id, content FROM {0} WHERE section = '{1}'\".format(table_name, section_dict[section]))\n",
    "\n",
    "        contents = cur.fetchall()\n",
    "        \n",
    "        unique_nouns = []\n",
    "        a_nouns = {}\n",
    "        a_noun_max_cnt = {}\n",
    "        inverted_idx = {}\n",
    "\n",
    "        for content_idx, content in enumerate(contents):\n",
    "            if (content_idx % 100) == 0:\n",
    "                print('{0:6,} / {1:6,}'.format(content_idx, len(contents)))\n",
    "\n",
    "            a_id = content[0]\n",
    "            a_nouns[a_id] = {}\n",
    "            nouns_cnt = {}\n",
    "            a_noun_max_cnt[a_id] = 0\n",
    "\n",
    "            # 연속된 공백 및 개행 제거\n",
    "            content = re.sub(r'[\\s]{2,}', ' ', content[1])\n",
    "            content = re.sub(r'[\\n]{2,}', '\\n', content)\n",
    "\n",
    "            # 문장 단위 토큰화\n",
    "            for idx, sentence in enumerate(nltk.sent_tokenize(content)):\n",
    "                nouns_temp = []\n",
    "\n",
    "        #         print(idx)\n",
    "        #         print('------------------------------')\n",
    "        #         print(sentence.strip())\n",
    "\n",
    "                # 단어 단위 토큰화\n",
    "                for word in nltk.word_tokenize(sentence.strip()):\n",
    "                    # 명사 추출\n",
    "                    nouns = k.nouns(word)\n",
    "                    \n",
    "                    stop_words = []\n",
    "\n",
    "                    for noun in nouns:\n",
    "                        # 기본 불용어 선별 (공통)\n",
    "                        # 길이가 1인 단어\n",
    "                        if len(noun) == 1:\n",
    "                            stop_words.append(noun)\n",
    "                            continue\n",
    "                        # 숫자만으로 이루어진 단어\n",
    "                        elif is_number(noun):\n",
    "                            stop_words.append(noun)\n",
    "                            continue\n",
    "\n",
    "                        # 기본 불용어 선별 (섹션별)\n",
    "                        # TODO:\n",
    "#                         if section == 'society':\n",
    "#                             pass\n",
    "#                         elif section == 'politics':\n",
    "#                             pass\n",
    "#                         elif section == 'economic':\n",
    "#                             pass\n",
    "#                         elif section == 'culture':\n",
    "#                             pass\n",
    "#                         elif section == 'digital':\n",
    "#                             pass\n",
    "#                         elif section == 'global':\n",
    "#                             pass\n",
    "\n",
    "                        if noun in nouns_cnt.keys():\n",
    "                            nouns_cnt[noun] += 1\n",
    "                        else:\n",
    "                            nouns_cnt[noun] = 1\n",
    "\n",
    "                        if a_noun_max_cnt[a_id] < nouns_cnt[noun]:\n",
    "                            a_noun_max_cnt[a_id] = nouns_cnt[noun]\n",
    "                    \n",
    "                    # 기본 불용어 제거\n",
    "                    for stop_word in stop_words:\n",
    "                        nouns.remove(stop_word)\n",
    "\n",
    "                    nouns_temp.extend(nouns)\n",
    "                    nouns_temp = list(set(nouns_temp))\n",
    "\n",
    "                unique_nouns.extend(nouns_temp)\n",
    "                unique_nouns = list(set(unique_nouns))\n",
    "                \n",
    "#                 print('------------------------------\\n\\n')\n",
    "\n",
    "            a_nouns[a_id] = nouns_cnt\n",
    "\n",
    "        for noun in unique_nouns:\n",
    "            inverted_idx[noun] = []\n",
    "\n",
    "            for a_id, nouns in a_nouns.items():\n",
    "                if noun in nouns:\n",
    "                    inverted_idx[noun].append(a_id)\n",
    "                    \n",
    "        if write:\n",
    "            print('Start to write files.')\n",
    "            \n",
    "            with open('index/original/' + section + '_unique_nouns.csv', 'w', newline='') as f:\n",
    "                csv_writer = csv.writer(f)\n",
    "                csv_writer.writerow(unique_nouns)\n",
    "\n",
    "            with open('index/original/' + section + '_article_nouns.csv', 'w', newline='') as f:\n",
    "                csv_writer = csv.writer(f)\n",
    "                for a_id, nouns in a_nouns.items():\n",
    "                    csv_writer.writerow([a_id, nouns])\n",
    "#                     for noun in nouns:\n",
    "#                         csv_writer.writerow([a_id, noun])\n",
    "\n",
    "#             with open('index/original/' + section + '_noun_max_count.csv', 'w', newline='') as f:\n",
    "#                 csv_writer = csv.writer(f)\n",
    "#                 for a_id, max_cnt in a_noun_max_cnt.items():\n",
    "#                     csv_writer.writerow([a_id, max_cnt])\n",
    "\n",
    "            with open('index/original/' + section + '_inverted_index.csv', 'w', newline='') as f:\n",
    "                csv_writer = csv.writer(f)\n",
    "                for noun, a_ids in inverted_idx.items():\n",
    "                    csv_writer.writerow([noun, a_ids])\n",
    "\n",
    "            with open('index/original/' + section + '_unique_nouns.pkl', 'wb') as f:\n",
    "                pickle.dump(unique_nouns, f)\n",
    "\n",
    "            with open('index/original/' + section + '_article_nouns.pkl', 'wb') as f:\n",
    "                pickle.dump(a_nouns, f)\n",
    "\n",
    "            with open('index/original/' + section + '_noun_max_count.pkl', 'wb') as f:\n",
    "                pickle.dump(a_noun_max_cnt, f)\n",
    "                \n",
    "            with open('index/original/' + section + '_inverted_index.pkl', 'wb') as f:\n",
    "                pickle.dump(inverted_idx, f)\n",
    "\n",
    "        print('\\n--------------------------------------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사회\n",
      "--------------------------------------------------\n",
      "\n",
      "     0 /    227\n",
      "   100 /    227\n",
      "   200 /    227\n",
      "Start to write files.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "정치\n",
      "--------------------------------------------------\n",
      "\n",
      "     0 /    257\n",
      "   100 /    257\n",
      "   200 /    257\n",
      "Start to write files.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "경제\n",
      "--------------------------------------------------\n",
      "\n",
      "     0 /    229\n",
      "   100 /    229\n",
      "   200 /    229\n",
      "Start to write files.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "문화\n",
      "--------------------------------------------------\n",
      "\n",
      "     0 /    199\n",
      "   100 /    199\n",
      "Start to write files.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "IT\n",
      "--------------------------------------------------\n",
      "\n",
      "     0 /    237\n",
      "   100 /    237\n",
      "   200 /    237\n",
      "Start to write files.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "세계\n",
      "--------------------------------------------------\n",
      "\n",
      "     0 /     65\n",
      "Start to write files.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inverted_index('daum', 'daum', write=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inverted_index('daum', 'daum', sections=['politics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Debug] Extract Nouns and Index Articles\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정치\n",
    "for section in section_list[1:2]:\n",
    "    with open('index/original/' + section + '_unique_nouns.pkl', 'rb') as f:\n",
    "        unique_nouns = pickle.load(f)\n",
    "    \n",
    "    with open('index/original/' + section + '_article_nouns.pkl', 'rb') as f:\n",
    "        a_nouns = pickle.load(f)\n",
    "        \n",
    "    with open('index/original/' + section + '_noun_max_count.pkl', 'rb') as f:\n",
    "        a_noun_max_cnt = pickle.load(f)\n",
    "        \n",
    "    with open('index/original/' + section + '_inverted_index.pkl', 'rb') as f:\n",
    "        inverted_idx = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "da_20180822211258392 \n",
      "\n",
      "6·13 지방선거에 바른미래당 서울시장 후보로 나섰다가 참패한 뒤 독일 등 해외에 머물겠다고 했던 안철수 전 의원이 서울 마포구에서 포착됐다.\n",
      "아주경제는 지난 21일 마포구의 한 사무실에서 기자와 마주치자 도망치는 안 전 의원의 모습(사진)을 22일 공개했다. 이 매체가 공개한 동영상에는 안 전 의원이 기자를 피해 황급히 계단을 내려가는 장면이 담겼다. 기자가 “죄를 지으신 게 아니지 않느냐”며 거듭 취재를 요청했지만 안 전 의원은 일절 답하지 않고 계단 아래쪽으로 뛰어 내려갔다.\n",
      "지난달 12일 안 전 의원은 기자회견을 열고 “정치 일선에서 물러나 통찰과 채움의 시간을 갖고자 한다”며 “대한민국이 당면한 시대적 난제를 앞서 해결하고 있는 독일에서 해결의 실마리를 얻겠다”고 말했었다. 그런 그가 당대표 선거가 한창인 지금 서울에 머물고 있는 게 의아하다는 반응도 나온다.\n",
      "안 전 의원이 서울에서 포착됐다는 보도에 대해 이준석 바른미래당 당대표 후보는 페이스북에 “이런 상황에서 음험한 계략을 꾸미는 분이 아니고 도망가실 분도 아니다. 그냥 바쁘셔서 그러셨을 거다”라고 썼다.\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('db/daum.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"SELECT a_id, content FROM daum WHERE section = '정치'\")\n",
    "\n",
    "a_id, content = cur.fetchone()\n",
    "\n",
    "print(a_id, '\\n')\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8198"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_nouns.sort()\n",
    "\n",
    "len(unique_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.2㎜',\n",
       " '0.4㎜',\n",
       " '0.6㎜',\n",
       " '0.86배',\n",
       " '0.95배',\n",
       " '08월',\n",
       " '1.43배',\n",
       " '1.4배',\n",
       " '1.5배',\n",
       " '10.5㎜']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_nouns[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "da_20180822211258392\n",
      "Max count:  6\n",
      "------------------------------\n",
      "\n",
      "계단 : 2\n",
      "공개 : 2\n",
      "기자 : 3\n",
      "당대표 : 2\n",
      "대표 : 2\n",
      "독일 : 2\n",
      "마포 : 2\n",
      "마포구 : 2\n",
      "미래 : 2\n",
      "미래당 : 2\n",
      "서울 : 4\n",
      "의원 : 6\n",
      "포착 : 2\n",
      "해결 : 2\n",
      "후보 : 2\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for a_id, nouns in a_nouns.items():\n",
    "    print(a_id)\n",
    "    print('Max count: ', a_noun_max_cnt[a_id])\n",
    "    print('------------------------------\\n')\n",
    "    \n",
    "    keys = list(nouns.keys())\n",
    "    keys.sort()\n",
    "    \n",
    "    for k in keys:\n",
    "        # 두 번 이상 나온 단어만 출력\n",
    "        if nouns[k] >= 2:\n",
    "            print('{0} : {1:,}'.format(k, nouns[k]))\n",
    "        else:\n",
    "#             print('{0} : {1:,}'.format(k, nouns[k]))\n",
    "            pass\n",
    "    \n",
    "    print('\\n------------------------------\\n\\n')\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10시 : 11\n",
      "제안 : 13\n",
      "기관 : 35\n",
      "조카 : 10\n",
      "박자 : 10\n",
      "압박 : 19\n",
      "여동생 : 13\n",
      "국방 : 26\n",
      "방안 : 35\n",
      "마련 : 28\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "for noun, a_ids in inverted_idx.items():\n",
    "    if cnt == 10:\n",
    "        break\n",
    "    \n",
    "    # 전체 기사에서 10번 이상 나온 단어만 출력 (10개)\n",
    "    if len(a_ids) >= 10:\n",
    "        print('{0} : {1:,}'.format(noun, len(a_ids)))\n",
    "        \n",
    "        cnt += 1\n",
    "    else:\n",
    "#         print('{0} : {1:,}'.format(noun, len(a_ids)))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF, DF and TF-IDF\n",
    "---\n",
    "\n",
    "* Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_ratio = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_nouns = {}\n",
    "a_nouns = {}\n",
    "a_noun_max_cnt = {}\n",
    "inverted_idx = {}\n",
    "\n",
    "for section in section_list:\n",
    "    with open('index/stopwords_removal/' + section + '_unique_nouns.pkl', 'rb') as f:\n",
    "        unique_nouns[section] = pickle.load(f)\n",
    "    \n",
    "    with open('index/stopwords_removal/' + section + '_article_nouns.pkl', 'rb') as f:\n",
    "        a_nouns[section] = pickle.load(f)\n",
    "        \n",
    "    with open('index/stopwords_removal/' + section + '_noun_max_count.pkl', 'rb') as f:\n",
    "        a_noun_max_cnt[section] = pickle.load(f)\n",
    "        \n",
    "    with open('index/stopwords_removal/' + section + '_inverted_index.pkl', 'rb') as f:\n",
    "        inverted_idx[section] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7410"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section = 'politics'\n",
    "\n",
    "len(unique_nouns[section])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기사별 TF\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "a_tf = {}\n",
    "\n",
    "for section in section_list:\n",
    "    print(section)\n",
    "    print('------------------------------\\n')\n",
    "    \n",
    "    a_tf[section] = {}\n",
    "\n",
    "    for a_id, nouns in a_nouns[section].items():\n",
    "        tf_temp = {}\n",
    "\n",
    "        for noun in nouns:\n",
    "            # Double normalization K\n",
    "            tf_temp[noun] = k_ratio + (1-  k_ratio) * (nouns[noun] / a_noun_max_cnt[section][a_id])\n",
    "            \n",
    "        a_tf[section][a_id] = tf_temp\n",
    "        \n",
    "        for noun in nouns:\n",
    "            if a_tf[section][a_id][noun] > 0.7:\n",
    "                print(a_id)\n",
    "                print(\"{0} | {1} + {2} * ({3} / {4}) = {5}\\n\".format(noun, k_ratio, (1 - k_ratio), nouns[noun], a_noun_max_cnt[section][a_id], tf_temp[noun]))\n",
    "                break\n",
    "                \n",
    "    print(len(a_tf[section]))\n",
    "    print('\\n------------------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# section = 'politics'\n",
    "# a_id = tuple(a_tf[section].keys())[0]\n",
    "\n",
    "# a_tf[section][a_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 섹션별 DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "society\n",
      "------------------------------\n",
      "\n",
      "바람 | 0.5 + 0.5 * (32 / 66) = 0.7424242424242424\n",
      "혐의 | 0.5 + 0.5 * (28 / 66) = 0.7121212121212122\n",
      "당시 | 0.5 + 0.5 * (28 / 66) = 0.7121212121212122\n",
      "필요 | 0.5 + 0.5 * (27 / 66) = 0.7045454545454546\n",
      "태풍 | 0.5 + 0.5 * (66 / 66) = 1.0\n",
      "한반도 | 0.5 + 0.5 * (27 / 66) = 0.7045454545454546\n",
      "솔릭 | 0.5 + 0.5 * (60 / 66) = 0.9545454545454546\n",
      "경찰 | 0.5 + 0.5 * (43 / 66) = 0.8257575757575757\n",
      "예상 | 0.5 + 0.5 * (34 / 66) = 0.7575757575757576\n",
      "안전 | 0.5 + 0.5 * (27 / 66) = 0.7045454545454546\n",
      "북상 | 0.5 + 0.5 * (35 / 66) = 0.7651515151515151\n",
      "강풍 | 0.5 + 0.5 * (33 / 66) = 0.75\n",
      "정부 | 0.5 + 0.5 * (31 / 66) = 0.7348484848484849\n",
      "앵커 | 0.5 + 0.5 * (41 / 66) = 0.8106060606060606\n",
      "제주 | 0.5 + 0.5 * (31 / 66) = 0.7348484848484849\n",
      "우려 | 0.5 + 0.5 * (36 / 66) = 0.7727272727272727\n",
      "서울 | 0.5 + 0.5 * (56 / 66) = 0.9242424242424243\n",
      "경기 | 0.5 + 0.5 * (41 / 66) = 0.8106060606060606\n",
      "조사 | 0.5 + 0.5 * (43 / 66) = 0.8257575757575757\n",
      "한국 | 0.5 + 0.5 * (35 / 66) = 0.7651515151515151\n",
      "비상 | 0.5 + 0.5 * (27 / 66) = 0.7045454545454546\n",
      "수사 | 0.5 + 0.5 * (27 / 66) = 0.7045454545454546\n",
      "지역 | 0.5 + 0.5 * (59 / 66) = 0.946969696969697\n",
      "현장 | 0.5 + 0.5 * (37 / 66) = 0.7803030303030303\n",
      "정도 | 0.5 + 0.5 * (27 / 66) = 0.7045454545454546\n",
      "지금 | 0.5 + 0.5 * (34 / 66) = 0.7575757575757576\n",
      "발생 | 0.5 + 0.5 * (32 / 66) = 0.7424242424242424\n",
      "피해 | 0.5 + 0.5 * (59 / 66) = 0.946969696969697\n",
      "\n",
      " 7083\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "politics\n",
      "------------------------------\n",
      "\n",
      "정책 | 0.5 + 0.5 * (54 / 113) = 0.7389380530973452\n",
      "생각 | 0.5 + 0.5 * (68 / 113) = 0.8008849557522124\n",
      "대통령 | 0.5 + 0.5 * (66 / 113) = 0.7920353982300885\n",
      "비판 | 0.5 + 0.5 * (49 / 113) = 0.7168141592920354\n",
      "설명 | 0.5 + 0.5 * (60 / 113) = 0.7654867256637168\n",
      "필요 | 0.5 + 0.5 * (48 / 113) = 0.7123893805309734\n",
      "지적 | 0.5 + 0.5 * (48 / 113) = 0.7123893805309734\n",
      "북한 | 0.5 + 0.5 * (49 / 113) = 0.7168141592920354\n",
      "국회 | 0.5 + 0.5 * (95 / 113) = 0.9203539823008849\n",
      "청와대 | 0.5 + 0.5 * (59 / 113) = 0.7610619469026549\n",
      "주장 | 0.5 + 0.5 * (49 / 113) = 0.7168141592920354\n",
      "경제 | 0.5 + 0.5 * (65 / 113) = 0.7876106194690266\n",
      "의원 | 0.5 + 0.5 * (92 / 113) = 0.9070796460176991\n",
      "정부 | 0.5 + 0.5 * (113 / 113) = 1.0\n",
      "남북 | 0.5 + 0.5 * (47 / 113) = 0.7079646017699115\n",
      "자유한국 | 0.5 + 0.5 * (56 / 113) = 0.747787610619469\n",
      "전체 | 0.5 + 0.5 * (48 / 113) = 0.7123893805309734\n",
      "서울 | 0.5 + 0.5 * (88 / 113) = 0.8893805309734513\n",
      "문재인 | 0.5 + 0.5 * (52 / 113) = 0.7300884955752213\n",
      "민주당 | 0.5 + 0.5 * (59 / 113) = 0.7610619469026549\n",
      "한국 | 0.5 + 0.5 * (88 / 113) = 0.8893805309734513\n",
      "인사 | 0.5 + 0.5 * (49 / 113) = 0.7168141592920354\n",
      "관계 | 0.5 + 0.5 * (47 / 113) = 0.7079646017699115\n",
      "미래 | 0.5 + 0.5 * (50 / 113) = 0.7212389380530974\n",
      "자유 | 0.5 + 0.5 * (72 / 113) = 0.8185840707964602\n",
      "일부 | 0.5 + 0.5 * (50 / 113) = 0.7212389380530974\n",
      "회의 | 0.5 + 0.5 * (71 / 113) = 0.8141592920353982\n",
      "국민 | 0.5 + 0.5 * (65 / 113) = 0.7876106194690266\n",
      "장관 | 0.5 + 0.5 * (65 / 113) = 0.7876106194690266\n",
      "\n",
      " 7410\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "economic\n",
      "------------------------------\n",
      "\n",
      "최저 | 0.5 + 0.5 * (32 / 79) = 0.7025316455696202\n",
      "금융 | 0.5 + 0.5 * (32 / 79) = 0.7025316455696202\n",
      "설명 | 0.5 + 0.5 * (36 / 79) = 0.7278481012658228\n",
      "필요 | 0.5 + 0.5 * (34 / 79) = 0.7151898734177216\n",
      "상공인 | 0.5 + 0.5 * (33 / 79) = 0.7088607594936709\n",
      "대책 | 0.5 + 0.5 * (45 / 79) = 0.7848101265822784\n",
      "결정 | 0.5 + 0.5 * (43 / 79) = 0.7721518987341772\n",
      "전망 | 0.5 + 0.5 * (38 / 79) = 0.740506329113924\n",
      "적용 | 0.5 + 0.5 * (41 / 79) = 0.759493670886076\n",
      "자금 | 0.5 + 0.5 * (41 / 79) = 0.759493670886076\n",
      "연간 | 0.5 + 0.5 * (33 / 79) = 0.7088607594936709\n",
      "경제 | 0.5 + 0.5 * (54 / 79) = 0.8417721518987342\n",
      "해당 | 0.5 + 0.5 * (37 / 79) = 0.7341772151898734\n",
      "매출 | 0.5 + 0.5 * (36 / 79) = 0.7278481012658228\n",
      "판매 | 0.5 + 0.5 * (33 / 79) = 0.7088607594936709\n",
      "부담 | 0.5 + 0.5 * (36 / 79) = 0.7278481012658228\n",
      "정부 | 0.5 + 0.5 * (53 / 79) = 0.8354430379746836\n",
      "사업 | 0.5 + 0.5 * (48 / 79) = 0.8037974683544304\n",
      "산업 | 0.5 + 0.5 * (37 / 79) = 0.7341772151898734\n",
      "투자 | 0.5 + 0.5 * (44 / 79) = 0.7784810126582278\n",
      "전체 | 0.5 + 0.5 * (33 / 79) = 0.7088607594936709\n",
      "서울 | 0.5 + 0.5 * (79 / 79) = 1.0\n",
      "강화 | 0.5 + 0.5 * (44 / 79) = 0.7784810126582278\n",
      "기업 | 0.5 + 0.5 * (52 / 79) = 0.8291139240506329\n",
      "한국 | 0.5 + 0.5 * (61 / 79) = 0.8860759493670887\n",
      "업체 | 0.5 + 0.5 * (33 / 79) = 0.7088607594936709\n",
      "금액 | 0.5 + 0.5 * (32 / 79) = 0.7025316455696202\n",
      "회사 | 0.5 + 0.5 * (38 / 79) = 0.740506329113924\n",
      "국내 | 0.5 + 0.5 * (37 / 79) = 0.7341772151898734\n",
      "개발 | 0.5 + 0.5 * (32 / 79) = 0.7025316455696202\n",
      "시장 | 0.5 + 0.5 * (48 / 79) = 0.8037974683544304\n",
      "카드 | 0.5 + 0.5 * (33 / 79) = 0.7088607594936709\n",
      "소상공인 | 0.5 + 0.5 * (32 / 79) = 0.7025316455696202\n",
      "\n",
      " 8413\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "culture\n",
      "------------------------------\n",
      "\n",
      "상륙 | 0.5 + 0.5 * (39 / 86) = 0.7267441860465116\n",
      "바람 | 0.5 + 0.5 * (53 / 86) = 0.8081395348837209\n",
      "비가 | 0.5 + 0.5 * (39 / 86) = 0.7267441860465116\n",
      "태풍 | 0.5 + 0.5 * (86 / 86) = 1.0\n",
      "한반도 | 0.5 + 0.5 * (40 / 86) = 0.7325581395348837\n",
      "솔릭 | 0.5 + 0.5 * (72 / 86) = 0.9186046511627908\n",
      "제주도 | 0.5 + 0.5 * (40 / 86) = 0.7325581395348837\n",
      "예상 | 0.5 + 0.5 * (59 / 86) = 0.8430232558139534\n",
      "해상 | 0.5 + 0.5 * (40 / 86) = 0.7325581395348837\n",
      "최고 | 0.5 + 0.5 * (42 / 86) = 0.7441860465116279\n",
      "사람 | 0.5 + 0.5 * (39 / 86) = 0.7267441860465116\n",
      "북상 | 0.5 + 0.5 * (46 / 86) = 0.7674418604651163\n",
      "강풍 | 0.5 + 0.5 * (41 / 86) = 0.7383720930232558\n",
      "전국 | 0.5 + 0.5 * (43 / 86) = 0.75\n",
      "서귀포 | 0.5 + 0.5 * (35 / 86) = 0.7034883720930233\n",
      "제주 | 0.5 + 0.5 * (59 / 86) = 0.8430232558139534\n",
      "전남 | 0.5 + 0.5 * (36 / 86) = 0.7093023255813954\n",
      "영향 | 0.5 + 0.5 * (42 / 86) = 0.7441860465116279\n",
      "서울 | 0.5 + 0.5 * (84 / 86) = 0.9883720930232558\n",
      "한국 | 0.5 + 0.5 * (46 / 86) = 0.7674418604651163\n",
      "내일 | 0.5 + 0.5 * (36 / 86) = 0.7093023255813954\n",
      "지역 | 0.5 + 0.5 * (60 / 86) = 0.8488372093023255\n",
      "지금 | 0.5 + 0.5 * (36 / 86) = 0.7093023255813954\n",
      "피해 | 0.5 + 0.5 * (37 / 86) = 0.7151162790697674\n",
      "\n",
      " 7992\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "digital\n",
      "------------------------------\n",
      "\n",
      "성장 | 0.5 + 0.5 * (49 / 101) = 0.7425742574257426\n",
      "미국 | 0.5 + 0.5 * (50 / 101) = 0.7475247524752475\n",
      "설명 | 0.5 + 0.5 * (65 / 101) = 0.8217821782178218\n",
      "확대 | 0.5 + 0.5 * (50 / 101) = 0.7475247524752475\n",
      "세계 | 0.5 + 0.5 * (45 / 101) = 0.7227722772277227\n",
      "필요 | 0.5 + 0.5 * (46 / 101) = 0.7277227722772277\n",
      "제품 | 0.5 + 0.5 * (54 / 101) = 0.7673267326732673\n",
      "데이터 | 0.5 + 0.5 * (41 / 101) = 0.7029702970297029\n",
      "모바일 | 0.5 + 0.5 * (45 / 101) = 0.7227722772277227\n",
      "적용 | 0.5 + 0.5 * (42 / 101) = 0.7079207920792079\n",
      "해외 | 0.5 + 0.5 * (48 / 101) = 0.7376237623762376\n",
      "사람 | 0.5 + 0.5 * (41 / 101) = 0.7029702970297029\n",
      "통신 | 0.5 + 0.5 * (63 / 101) = 0.8118811881188119\n",
      "기반 | 0.5 + 0.5 * (51 / 101) = 0.7524752475247525\n",
      "사업 | 0.5 + 0.5 * (63 / 101) = 0.8118811881188119\n",
      "산업 | 0.5 + 0.5 * (47 / 101) = 0.7326732673267327\n",
      "서비스 | 0.5 + 0.5 * (95 / 101) = 0.9702970297029703\n",
      "서울 | 0.5 + 0.5 * (81 / 101) = 0.900990099009901\n",
      "시작 | 0.5 + 0.5 * (41 / 101) = 0.7029702970297029\n",
      "기업 | 0.5 + 0.5 * (71 / 101) = 0.8514851485148515\n",
      "정보 | 0.5 + 0.5 * (70 / 101) = 0.8465346534653465\n",
      "한국 | 0.5 + 0.5 * (73 / 101) = 0.8613861386138614\n",
      "업체 | 0.5 + 0.5 * (47 / 101) = 0.7326732673267327\n",
      "회사 | 0.5 + 0.5 * (45 / 101) = 0.7227722772277227\n",
      "국내 | 0.5 + 0.5 * (65 / 101) = 0.8217821782178218\n",
      "출시 | 0.5 + 0.5 * (49 / 101) = 0.7425742574257426\n",
      "개발 | 0.5 + 0.5 * (59 / 101) = 0.7920792079207921\n",
      "기술 | 0.5 + 0.5 * (101 / 101) = 1.0\n",
      "시장 | 0.5 + 0.5 * (95 / 101) = 0.9702970297029703\n",
      "플랫폼 | 0.5 + 0.5 * (43 / 101) = 0.7128712871287128\n",
      "\n",
      " 8474\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "global\n",
      "------------------------------\n",
      "\n",
      "인도네시아 | 0.5 + 0.5 * (37 / 49) = 0.8775510204081632\n",
      "게임 | 0.5 + 0.5 * (26 / 49) = 0.7653061224489797\n",
      "여자 | 0.5 + 0.5 * (29 / 49) = 0.7959183673469388\n",
      "현지시간 | 0.5 + 0.5 * (39 / 49) = 0.8979591836734694\n",
      "경기장 | 0.5 + 0.5 * (25 / 49) = 0.7551020408163265\n",
      "중국 | 0.5 + 0.5 * (20 / 49) = 0.7040816326530612\n",
      "현지 | 0.5 + 0.5 * (49 / 49) = 1.0\n",
      "아시안 | 0.5 + 0.5 * (26 / 49) = 0.7653061224489797\n",
      "아시안게임 | 0.5 + 0.5 * (26 / 49) = 0.7653061224489797\n",
      "팔렘방 | 0.5 + 0.5 * (38 / 49) = 0.8877551020408163\n",
      "자카르타 | 0.5 + 0.5 * (26 / 49) = 0.7653061224489797\n",
      "\n",
      " 1657\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_df = {}\n",
    "a_max_cnt = {}\n",
    "\n",
    "for section in section_list:\n",
    "    print(section)\n",
    "    print('------------------------------\\n')\n",
    "    \n",
    "    # Section의 article 수\n",
    "    a_size = len(a_tf[section])\n",
    "    a_max_cnt[section] = 0\n",
    "    s_df[section] = {}\n",
    "    \n",
    "    for _, a_ids in inverted_idx[section].items():\n",
    "        if a_max_cnt[section] < len(a_ids):\n",
    "            a_max_cnt[section] = len(a_ids)\n",
    "    \n",
    "    for noun, a_ids in inverted_idx[section].items():\n",
    "        # Double normalization K\n",
    "        s_df[section][noun] = k_ratio + (1-  k_ratio) * (len(a_ids) / a_max_cnt[section])\n",
    "        \n",
    "        if s_df[section][noun] > 0.7:\n",
    "            print(\"{0} | {1} + {2} * ({3} / {4}) = {5}\".format(noun, k_ratio, (1 - k_ratio), len(a_ids), a_max_cnt[section], s_df[section][noun]))\n",
    "\n",
    "    print('\\n', len(s_df[section]))\n",
    "    print('\\n------------------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section = 'politics'\n",
    "# # noun = tuple(s_df[section].keys())[0]\n",
    "\n",
    "# s_df[section]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
